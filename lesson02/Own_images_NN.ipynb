{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MiroPol21/dspracticum2025/blob/main/lesson02/Own_images_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5j8Ih8JeWh8"
      },
      "source": [
        "Let's build a simple neural network to classify images.\n",
        "\n",
        "**1. Install ddgs package**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run only once\n",
        "!pip install ddgs"
      ],
      "metadata": {
        "collapsed": true,
        "id": "umrk5Tygla-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Import libraries**"
      ],
      "metadata": {
        "id": "JgpXcTFsl4K4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBQVdt1S-MT9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "from ddgs import DDGS\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Import images**"
      ],
      "metadata": {
        "id": "fDw2Gl-lmJFj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_images(keyword, max_results=10):\n",
        "    with DDGS() as ddgs:\n",
        "        images = ddgs.images(\n",
        "            keyword,\n",
        "            max_results=max_results\n",
        "        )\n",
        "        return [img['image'] for img in images]"
      ],
      "metadata": {
        "id": "nSUWiuxOlkVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword = \"people cafe\"\n",
        "image_urls = search_images(keyword, 1000)\n",
        "len(image_urls)"
      ],
      "metadata": {
        "id": "SGJJDjh6nQFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_urls[24]"
      ],
      "metadata": {
        "id": "hNOmQHJVngV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Download Images**"
      ],
      "metadata": {
        "id": "g1FmHRWWoTak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_image(url, folder, custom_name=None, verbose=True):\n",
        "    # Create the folder if it doesn't exist\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    # Get the filename from the URL or use the custom name\n",
        "    if custom_name:\n",
        "        filename = custom_name\n",
        "    else:\n",
        "        filename = os.path.basename(urlparse(url).path)\n",
        "        if not filename:\n",
        "            filename = 'image.jpg'  # Default filename if none is found in the URL\n",
        "\n",
        "    # Ensure the filename has an extension\n",
        "    if not os.path.splitext(filename)[1]:\n",
        "        filename += '.jpg'\n",
        "\n",
        "    filepath = os.path.join(folder, filename)\n",
        "\n",
        "    # If the file already exists, append a number to make it unique\n",
        "    base, extension = os.path.splitext(filepath)\n",
        "    counter = 1\n",
        "    while os.path.exists(filepath):\n",
        "        filepath = f\"{base}_{counter}{extension}\"\n",
        "        counter += 1\n",
        "\n",
        "    try:\n",
        "        # Send a GET request to the URL with a timeout of 10 seconds\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()  # Raises an HTTPError for bad responses\n",
        "\n",
        "        # Check if the content type is an image\n",
        "        content_type = response.headers.get('content-type', '')\n",
        "        if not content_type.startswith('image'):\n",
        "            if verbose:\n",
        "                warnings.warn(f\"The URL does not point to an image. Content-Type: {content_type}\")\n",
        "            return False\n",
        "\n",
        "        # Write the image content to the file\n",
        "        with open(filepath, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"Image successfully downloaded: {filepath}\")\n",
        "        return True\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "        if verbose:\n",
        "            warnings.warn(f\"Download timed out for URL: {url}\")\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        if verbose:\n",
        "            warnings.warn(f\"HTTP error occurred: {e}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        if verbose:\n",
        "            warnings.warn(f\"An error occurred while downloading the image: {e}\")\n",
        "    except IOError as e:\n",
        "        if verbose:\n",
        "            warnings.warn(f\"An error occurred while writing the file: {e}\")\n"
      ],
      "metadata": {
        "id": "_o72Se5noWCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "for i, url in enumerate(tqdm(image_urls)):\n",
        "    download_image(url, \"./dataset/people_cafe/\", f'image{i}.jpg', verbose=False)"
      ],
      "metadata": {
        "id": "wz3eD-t5oXcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e143603"
      },
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import warnings\n",
        "\n",
        "def remove_invalid_images(directory):\n",
        "    \"\"\"\n",
        "    Removes files from a directory that are not valid images.\n",
        "    \"\"\"\n",
        "    print(f\"Checking directory: {directory}\")\n",
        "    for subdir, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            filepath = os.path.join(subdir, file)\n",
        "            try:\n",
        "                with warnings.catch_warnings():\n",
        "                    warnings.simplefilter(\"ignore\", Image.DecompressionBombWarning)\n",
        "                    img = Image.open(filepath)\n",
        "                    img.verify() # Verify that it is an image\n",
        "            except Exception:\n",
        "                # If verification fails, delete the file\n",
        "                if os.path.exists(filepath):\n",
        "                    print(f\"Removing invalid image: {filepath}\")\n",
        "                    os.remove(filepath)\n",
        "\n",
        "remove_invalid_images('./dataset')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ...\n",
        "from torchvision import datasets, transforms\n",
        "# ...\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the dataset\n",
        "dataset = datasets.ImageFolder(root='./dataset', transform=transform)"
      ],
      "metadata": {
        "id": "Jz1eV_Dpo268"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset\n",
        "\n",
        "# print(\"Classes:\", dataset.classes)"
      ],
      "metadata": {
        "id": "sq2ud4GzuH5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_tensor = dataset[471]\n",
        "\n",
        "# If it's a tuple like (tensor, label), unpack it:\n",
        "if isinstance(img_tensor, tuple):\n",
        "    img_tensor, label = img_tensor\n",
        "\n",
        "# Convert from (C, H, W) to (H, W, C)\n",
        "img = img_tensor.permute(1, 2, 0).numpy()\n",
        "\n",
        "# Plot\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "o0g0giqhsYwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhodnFckeudX"
      },
      "source": [
        "*Checking for GPU Availability*\n",
        "\n",
        "This code checks if a CUDA-enabled GPU is available and sets the `device` accordingly. If no GPU is available, it defaults to the CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dFBM3DFB60w"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abf1Alkfe302"
      },
      "source": [
        "**2. Data Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K47TtwmA-Z8x"
      },
      "outputs": [],
      "source": [
        "# --- 3. Split into train/test ---\n",
        "train_size = int(0.8 * len(dataset))  # 80% train, 20% test\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "# --- 4. Wrap in DataLoaders ---\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KD7S6DsPe8ym"
      },
      "source": [
        "**3. Neural Network Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twFKRzDA-lnB"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
        "        self.flat = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(in_features=124*124*64, out_features=128)\n",
        "        self.drop = nn.Dropout(0.25)\n",
        "        self.fc2 = nn.Linear(in_features=128, out_features=6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.flat(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN().to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1FrTseTgr29"
      },
      "source": [
        "**4. Loss & Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJPpEm9n-zB6"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.02)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HncQZoLcgywM"
      },
      "source": [
        "**5. Training loop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PYUAF99_Qsc"
      },
      "outputs": [],
      "source": [
        "for epoch in range(5):  # Train for 5 epochs\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        # Move images and labels to the device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch [{epoch+1}/5], Loss: {running_loss / len(train_loader):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4qK5d5Og608"
      },
      "source": [
        "**6. Evaluation on the test set**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQTk85Jt_TXb"
      },
      "outputs": [],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
        "    for images, labels in test_loader:\n",
        "        # Move images and labels to the device\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy: {100 * correct / total:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeLdrT_jC4wn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Get one batch from test_loader\n",
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "# Move to device\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "\n",
        "# Get predictions\n",
        "outputs = model(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Pick the nth image in the batch\n",
        "n=11 # n=4,5 top\n",
        "img = images[n].cpu().permute(1, 2, 0).numpy()  # (C,H,W) -> (H,W,C)\n",
        "true_label = dataset.classes[labels[n].item()]\n",
        "pred_label = dataset.classes[predicted[n].item()]\n",
        "\n",
        "# Show the image\n",
        "plt.imshow(img)\n",
        "plt.axis(\"off\")\n",
        "plt.title(f\"True: {true_label} | Pred: {pred_label}\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}